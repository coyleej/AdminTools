\chapter{Slurm setup and administration} \label{ch:slurmsetup}

\textbf{\emph{This setup works on Ubuntu 18.04.}}

SchedMD recommends a separate database server if possible. It may be on the same server as \texttt{slurmctld}, but this may impact performance. You should consider optimizing the database performance by mounting the MariaDB or MySQL database directory on a dedicated high-speed file system. Ideally this would be a PCIe SSD disk drive (e.g.\ Intel SSD P3700 series or Kingston E1000 series), but SSD SAS/SATA will also work. Drives must be qualified for high-volume random small read/write operations, and should be built with the Non-Volatile Memory Express (NVMe) storage interface standard for reliability and performance. A disk size of 200 GB or 400 GB should be sufficient. Consider installing 2 disk drives in a RAID-1 configuration.

The following will be installed in this setup guide:

\begin{itemize}
\item MPI : OpenMPI version 2
\item Slurm 17.11.2-1
\item Authentication and digital signatures: MUNGE
\item Database : MariaDB
\end{itemize}

\section{Reference materials} \label{sec:slurmguides}

This guide was constructed from the following references and my own experiences:

\href{https://slurm.schedmd.com/quickstart_admin.html}{Slurm admin quick-start} \\
\indent \href{https://slurm.schedmd.com/documentation.html}{Slurm official documentation} \\
\indent \href{slurm-wlm-doc} for Slurm 17.11.2-1build1
\indent \href{https://slurm.schedmd.com/man_index.html}{Slurm man pages and configuration file index} \\
\indent \href{https://slurm.schedmd.com/mc_support.html}{Slurm multi-core support} \\
\indent \href{https://slurm.schedmd.com/download.html}{Slurm download and addons list} \\
\indent \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration}{Slurm configuration (Niflheim)} \\
\indent \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_database}{Slurm database (Niflheim)} \\
\indent \href{https://github.com/dholt/slurm-gpu}{Slurm-gpu github}

\section{Basic Slurm set up} \label{sec:basicslurm}

\begin{enumerate}
\item If you intend to set up a database on its own high speed drive, mount the drive now. % Default database location is /var/lib/mysql

%%%%%%%% INSTALL REQUIRED PACKAGES %%%%%%%%
\item Make sure that OpenMPI is installed. If not, install it with

	\texttt{sudo apt install libopenmpi2 libopenmpi-dev openmpi-common openmpi-doc}

\item Download the \href{https://github.com/coyleej/MiniClusterTools}{MiniClusterTools repo}  if you haven't already. It contains a slurm installation script.

	\texttt{git clone https://github.com/coyleej/MiniClusterTools.git}

%%%%%%%% BASH SCRIPT %%%%%%%%
\item Run \texttt{install\_slurm.sh}. It automates much of the setup. The following explains what it does.

	\texttt{bash install\_slurm.sh}

	\begin{enumerate}
	\item Create Munge user with \texttt{uid} and \texttt{gid} of 399. (Can be any \emph{unused} value between SYS\_UID\_MIN and SYS\_UID\_MAX, which are defined in \texttt{/etc/login.defs}). 

		\texttt{mungeUID=399} \\
		\texttt{sudo groupadd -g \$mungeUID munge} \\
		\texttt{sudo useradd -r -u \$mungeUID -g \$mungeUID munge} \\
		\texttt{sudo usermod -d /nonexistent munge}

	\item Make sure the system clock is set to the correct timezone and confirm that your system clock is correct:

		\texttt{sudo timedatectl set-timezone America/New\_York} \\
		\texttt{timedatectl}

	\item Check that \texttt{nvidia-driver-418} or newer is installed so that slurm can find the GPUs.

		\begin{enumerate}
		\item Check that we're using the Ubuntu \texttt{graphics-drivers} PPA. If we aren't:

			\texttt{sudo add-apt-repository ppa:graphics-drivers/ppa} \\
			\texttt{sudo apt update}

		\item Use \texttt{apt} to purge anything older than \texttt{nvidia-driver-418}.

		\item Use \texttt{apt} to install \texttt{nvidia-driver-418} if neither it nor a newer version are present.

		\end{enumerate}

	\item Install OpenMPI if it is not presently installed:

		\texttt{sudo apt install libopenmpi2 libopenmpi-dev openmpi-common openmpi-doc}

	\item Install MUNGE, SLURM, MySQL, MariaDB, and cgroup-tools: \\
		\texttt{apt install munge libmunge-dev libpam-slurm slurmd slurmdbd slurm-wlm-doc \\ cgroup-tools mariadb-common mariadb-server} % mysql-common mysql-server}

	\item If the node in question is the control node or the backup control node:

		\texttt{sudo apt install slurmctld slurm-wlm slurmdbd}

		Otherwise:

		\texttt{sudo apt install slurm-client} 

	\item User prompts will gather some information on GPUs.

%%%%%%%% CONTROL NODE CONFIGURATION %%%%%%%%
	\item Configure the control node, if applicable. 

		\begin{enumerate}
		\item Make sure that \texttt{/var/spool/slurmctld/} and \texttt{/var/log/slurm-llnl/} exist. If not, create them with \texttt{mkdir}.

		\item Make sure that slurm is the owner of these directories. If not, use \texttt{chown slurm: <dirname>}.

		\item Make sure that the permissions on these directories are set to \texttt{755}. If not, use \texttt{chmod}.

		\item Check that \texttt{/var/log/slurm-llnl/slurmctld.log} exists and is owned by slurm. Otherwise, create it using \texttt{touch} and \texttt{chown}.

		\item Create the Linux default accounting file.

			\texttt{sudo touch /var/log/slurm-llnl/slurm\_jobacct.log} \\
			\texttt{sudo chown slurm: /var/log/slurm-llnl/slurm\_jobacct.log } \\
			\texttt{sudo touch /var/log/slurm-llnl/slurm\_jobcomp.log} \\
			\texttt{sudo chown slurm: /var/log/slurm-llnl/slurm\_jobcomp.log}

		\end{enumerate}

%%%%%%%% COMPUTE NODE CONFIGURATION %%%%%%%%
	\item Configure the compute nodes. See \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#id12}{this site} for further details. 

		\begin{enumerate}
		\item Create the \texttt{slurmd} spool directory with the correct ownership.

			\texttt{mkdir /var/spool/slurmd} \\% /var/log/slurm} \\
			\texttt{chown slurm: /var/spool/slurmd} \\%  /var/log/slurm} \\
			\texttt{chmod 755 /var/spool/slurmd}% /var/log/slurm} 

		\item Create the log files:

			\texttt{touch /var/log/slurmd.log} \\
			\texttt{chown slurm: /var/log/slurmd.log}
	
		\item Create the pid files (only need \texttt{slurmctld.pid} on the control node:

			\texttt{touch /var/log/slurm-llnl/slurmd.pid /var/log/slurm-llnl/slurmctld.pid} \\
			\texttt{chown slurm: /var/log/slurm-llnl/slurmd.pid /var/log/slurm-llnl/slurmctld.pid}

		\item View the physical configuration (sockets, cores, real memory, etc.) of each of the compute nodes with the command \texttt{slurmd -C}, and update this information in \texttt{slurm.conf} file.

		\item Set the \texttt{State} of the node as UNKNOWN (slurm assigns BUSY or IDLE) or FUTURE.

		\item It may be a good idea to assign weights to the compute nodes. All things being equal, jobs will be allocated the nodes with the lowest weight. The enables prioritization based upon hardware parameters such as GPUs, RAM, CPU clock speed, CPU core number, CPU generation. (\href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#node-weight}{more info})

		\item It may be a good idea in the future to uncomment \texttt{TmpFS=} in \texttt{slurm.conf}. (\texttt{/tmp} is the default; can change to e.g.\ \texttt{/scratch}.) You can add \texttt{TmpDisk=xxxxx} to each compute node line, where \texttt{xxxxx} is the size of the temporary file system.

		\end{enumerate}

%%%%%%%% MORE SPOOL! %%%%%%%%
	\item Create spool directories:
	
	\texttt{mkdir -p /var/spool/slurm/d} \\
	\texttt{mkdir /var/spool/slurm/ctld} \\
	\texttt{chown slurm: /var/spool/slurm /var/spool/slurm/d /var/spool/slurm/ctld}
	
%%%%%%%% GRES.CONF %%%%%%%%
	\item Create a \texttt{gres.conf} file. 

	Inside this file, add a line for each GPU available on that node as follows: \texttt{Name=gpu Type=<type> File=/dev/nvidia\#}. (Confirm numbers with \texttt{ls -l /dev/nvidia*}.) See \href{https://slurm.schedmd.com/gres.conf.html}{the documentation} for more options.

%%%%%%%% CGROUP.CONF %%%%%%%%
	\item Copy \texttt{cgroup.conf.example} into \texttt{cgroup.conf} and make the following changes:

		\begin{enumerate}
		\item \texttt{ConstrainCores=no}
		\item \texttt{ConstrainRAMSpace=yes} (change from no)
		\item You may also want to include \texttt{MemSpecLimit} and \texttt{ContrainKmemSpace}.  (\href{https://www.mankier.com/5/cgroup.conf}{reference material})
		\end{enumerate}
		
	\item Adjust the grub configuration. Open \texttt{/etc/default/grub} 
	
	Add \texttt{cgroup\_enable=memory swapaccount=1} to  \texttt{GRUB\_CMDLINE\_LINUX} line.
	
	Run \texttt{update-grub}.

	\item Check the node configuration as detected by slurm by typing \texttt{slurmd -C} into the command line. Adjust the appropriate line of the COMPUTE NODES section of the \texttt{slurm.conf} file to match.

	\item Retrieve the configuration files:

		\begin{enumerate}
		\item Determine your version of slurm by typing \texttt{dpkg -l | grep slurm}. It should report version 17.11.2-1build1. 
	
		\item Obtain the code directly from the command line with: \\ 
	\texttt{wget https://github.com/SchedMD/slurm/archive/slurm-17-11-2-1.tar.gz}
	 
		\item Extract the files. The example configuration files are in \texttt{<unzipped-slurm>/etc/}. Copy all example config files into \texttt{/etc/slurm-llnl/}
	\end{enumerate}

%%%%%%%% SLURM.CONF %%%%%%%%
	\item Copy \texttt{slurm.conf.example} to \texttt{slurm.conf} and make the following changes (e.g.\ on thanos):

		\begin{enumerate}
		\item \texttt{ClusterName=Marvel}
		\item \texttt{ControlMachine=magneto}
		\item \texttt{ProctrackType=proctrack/cgroup}	
		\item \texttt{TaskPlugin=task/cgroup}
		\item \texttt{InactiveLimit=600}	
		\item \texttt{NodeName=thanos}
		\item \texttt{Nodes=thanos}
		\item \texttt{PartitionName=CEM}

		\item Remove \texttt{Procs=1} and replace it with \texttt{CPUs=128}. (On a multi-core/hyperthreaded system, slurm uses the number of threads as the number of CPUs)

		\item Add a RESOURCES section just above COMPUTE NODES with the following: \texttt{GresTypes=gpu}.

		\item In the COMPUTE NODES, add the following to each node containing one or more GPUs. \# is the number of available GPUs on that node: \texttt{Gres=gpu:\#}. Insert this just before \texttt{State=UNKNOWN}.

		\item In the SCHEDULING section, set the default memory per node at 1000 MB. (Slurm's default is ALL, which will not allow multiple jobs simultaneously.) \\
		DefMemPerNode=1000

		\item Change the location of the slurm PID files to the following:

		\texttt{SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid} \\ %# originally in /var/run/
		\texttt{SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid} % # originally in /var/run/

		\item Modify \texttt{slurm.conf} so that the nodes can be rebooted while slurm is running. Change the reboot program to \texttt{RebootProgram="/sbin/reboot"}. 
		
		\item Check that \texttt{StateSaveLocation=/var/spool/slurm/ctld}. This directory should already exist, but doublecheck to make sure.

%%%%%%%% RESOURCES SETTINGS %%%%%%%%
		\item Check that \texttt{FastSchedule=1} and \texttt{SchedulerType=sched/backfill} (default settings).
	
		\item Set the consumable resources (\href{https://slurm.schedmd.com/cons_res.html}{1} and \href{https://slurm.schedmd.com/cons_res_share.html}{2}):
		\texttt{SelectType=select/cons\_res}
	
		\item You must also select what is allowed as consumable resources. In \texttt{slurm.conf}, set \\
		\texttt{SelectTypeParameters=CR\_CPU\_Memory}. 
	
		NOTE: If you use memory as a consumable resource, you \emph{must} set the \texttt{RealMemory} parameter.
	
		NOTE: If CPUs are a consumable resource, Slurm has no notion of sockets, cores, or threads. On single- and multi-core systems, CPU refers to cores. On a multi-core/hyperthread system CPU refers to threads.
	
		\item Because both CPUs and Memory are consumable resources, you \emph{must} set \texttt{OverSubscribe=NO} to prevent jobs from conflicting with one another. Strange behavior will occur if \texttt{OverSubscribe=YES}, as jobs will conflict with one another. %Also, slurm automatically assigns all memory to a job by default, so the line \texttt{\#SBATCH --mem=X} must be specified if more than one job is to run simultaneously. 

%%%%%%%% PARTITION CONFIGURATION %%%%%%%%
		\item Configure the partitions in \texttt{slurm.conf}, for example: \\
		\texttt{PartitionName=xeon8 Nodes=a[070-080] Default=YES DefaultTime=50:00:00 \\ MaxTime=168:00:00 State=UNKNOWN}

		In the SCHEDULING section of the \texttt{slurm.conf} file, set \texttt{EnforcePartLimits=YES}. This will reject jobs that exceed a partition's size and/or time limits when they're submitted.

		Things to keep in mind for the future (\emph{\textbf{not setting these up}}):
			\begin{itemize}
			\item Partitions may overlap so that some nodes belong to several partitions. 
	
			\item Access to partitions is configured in \texttt{slurm.conf} using AllowAccounts, AllowGroups, or AllowQos.
	
			\item If some partitions (e.g.\ big memory nodes) should have a higher priority, set this in \texttt{slurm.conf} using the multifactor plugin:
			\texttt{PartitionName ... PriorityJobFactor=10} \\
			\texttt{PriorityWeightPartition=1000}
			\end{itemize}

%%%%%%%% LIMIT PROPAGATION %%%%%%%%
		\item By default, slurm propagates all user limits from the submitting node (see \texttt{ulimit -a} to the batch jobs. Configure \texttt{slurm.conf} so that the locked memory limit isn't propagated by uncommenting and setting as follows: \\
		\texttt{PropagateResourceLimitsExcept=MEMLOCK}
	
		(We haven't done the following, but if you have imposed any non-default limits on the login nodes in \texttt{/etc/security/limits.conf} or \texttt{/etc/security/limits.d/*.conf}, you probably want to prohibit these by setting: 
		\texttt{PropagateResourceLimitsExcept=ALL}
	
		See the slurm documentation for available options.)

%%%%%%%% PLUGIN LOCATION %%%%%%%%
		\item Do NOT modify \texttt{\#PluginDir}! Doing so causes slurm to crash. Slurm defaults to: \\
		\texttt{usr/lib/x86\_64-linux-gnu/slurm-wlm}
		\end{enumerate} 

	\item Start \texttt{slurmd} and, if applicable, \texttt{slurmctld}.

	\texttt{sudo systemctl start slurmd} \\
	\texttt{sudo systemctl start slurmctld \quad \# if applicable}

	You will get a warning or error if \texttt{slurmd -C} failed and the code autofilled the laptop values.

	\item Removes the extracted folder. The downloaded compressed folder is left untouched.
	
	\item End of installation script.
	\end{enumerate}
	
%%%%%%%% ADJUSTMENTS FOLLOWING SCRIPT EXECUTION %%%%%%%%
\item Check that the \texttt{NodeName} line matches the output of \texttt{slurmd -C}. If \texttt{slurmd -C} fails to execute properly, \texttt{install\_slurm.sh} autofills with the values for an Oryx Pro.

\item Resolve any errors that popped up when running the installation script.

	\begin{enumerate}
	\item If the daemon(s) failed to start, type \texttt{systemctl status <daemon>}. If slurm can't find nodes or a machine name, fix the \texttt{slurm.conf} and try again. 

	\item If slurm complains that it doesn't have permissions to access a directory, you probably forgot \texttt{sudo} when starting slurm.

	\item If slurm isn't starting because it is missing directories, manually create those directories, set \texttt{slurm} as the owner, and try again.

	\item If slurm claims to be missing any configuration files (\texttt{*.conf}), see if it exists in \texttt{/etc/slurm-llnl} as \texttt{*.conf.example}. If it does, copy it, modify it, and try again. If it doesn't exist, refer to the source code on github for \texttt{your version of slurm} and copy it where it needs to go.

	\item If slurm can't find the GPUs, make sure that the system can see the GPUs and that you have an appropriate Nvidia driver.

	\item If it's still not working, start slurm manually (section \ref{subsec:manualstart}) to see more detailed error messages. 
	\end{enumerate}

\item \emph{At present the script only handles local setup}. 

	\begin{enumerate}
	\item \texttt{slurm.conf} -- Nodes and partitions on remote machines must be added manually. The rest of the file will be the same, so all that will be required is copy/pasting the node and partition information between files. You need to add \texttt{NodeAddr=<IP>} to all of the compute nodes. Add this just after \texttt{NodeName=<name>}.

	\item \emph{Copy the proper munge key} into \texttt{/etc/munge}, then restart the \texttt{munge} and \texttt{slurmd} daemons.
	\end{enumerate}

\item If you installed slurm with \texttt{install\_slurm.sh}, \texttt{cgroup.conf} will be the same on all nodes and all the \texttt{gres.conf} files will be setup appropriately. If you did not use the script, make sure that \texttt{cgroup.conf} is the same on all compute nodes and add \texttt{gres.conf} files as necessary.

\item Restart the node.

%%%%%%%% MUNGE %%%%%%%%
\item Check that munge is setup properly. \label{list:munge}
	\begin{enumerate}
	\item If munge is already running, stop it with \texttt{systemctl stop munge}.

	\item Check that the following files/directories are owned by \texttt{munge} instead of \texttt{root}: \\
	\texttt{/etc/munge}, 
	\texttt{/usr/bin/munge}, 
	\texttt{/usr/sbin/munged}, 
	\texttt{/var/lib/munge}, 
	\texttt{/var/log/munge}, \\
	\texttt{/var/run/munge}

	\item Create a munge key on the control node with \texttt{sudo /usr/sbin/create-munge-key}. (Ubuntu may have already done this for you.) 

	\item On the controller, make sure the munge key (\texttt{munge.key}) is in \texttt{/etc/munge/munge.key} and change the owner to munge.  

	\item Copy the key from the control node to all existing compute nodes: 

		\texttt{sudo scp /etc/munge/munge.key admin@compute-node:/home/<admin>/}

	\item On the compute nodes, move the \texttt{munge.key} into \texttt{/etc/munge}. Make sure that it is owned by \texttt{munge} with file permissions \texttt{400}.

	\item Make sure that munge is enabled and (re)start it on all machines:

		\texttt{sudo systemctl start munge}

	\item Check if munge is running by typing \texttt{systemctl status munge}.

	\item Test munge: \addcontentsline{lot}{table}{Munge test commands}

	    Generate a credential on stdout: \\
	    \texttt{munge -n} \\
	    Check if a credential can be locally decoded: \\
	    \texttt{munge -n | unmunge} \\
	    Check if a credential can be remotely decoded: \\
	    \texttt{munge -n | ssh <admin>@<node> unmunge} \\
	    Run a quick benchmark: \\
	    \texttt{remunge}

	\end{enumerate}

%%%%%%%% START SLURM %%%%%%%%
\item Start slurm. Don't worry about enabling the daemons just yet; that will happen later.

	\texttt{sudo systemctl start slurmctld} \# Control node \\
	\texttt{sudo systemctl start slurmd} \# Compute nodes 

\item Test that the job submission is working. The submission command is \texttt{sbatch <script-name>}. To check the status of the job, type \texttt{squeue}. Output will be written in the same folder as the script. Refer to section \ref{sec:slurmscripts} for an explanation of the SBATCH directives.

A very basic test script:
\begin{verbatim}
	#!/bin/bash
	#SBATCH --job-name="testjob"
	#SBATCH --time=2:00:00
	echo "running job"
	sleep 120
	echo "All done! :)"
\end{verbatim}

A slightly less basic test script (\%x is the job name and \%j is the job number):
\begin{verbatim}
	#!/bin/bash
	#SBATCH --job-name=example
	#SBATCH --cpus-per-task=1
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=1
	#SBATCH --time=10:00
	#SBATCH --mem=1000
	#SBATCH --partition=CEM
	#SBATCH --output=%x.o%j

	python temp.py
	sleep 120
\end{verbatim}

\emph{Note: Both of these test scripts contain the \emph{\texttt{sleep}} command specifically to keep the job ``running" for a longer time; it is not necessary for actual jobs.}

\item Stop the slurm daemons: 

	\texttt{systemd}: \texttt{sudo systemctl stop <daemon>} \\
	Manual start: \texttt{Ctrl-C}

%%%%%%%% PROLOG & EPILOG %%%%%%%%
\item We are using the default Prolog and Epilog scripts. Refer to the \href{https://slurm.schedmd.com/slurm.conf.html}{documentation} if this changes.

\item Restart the node.
	
\item Start slurm and test the queue to confirm that it can run multiple jobs simultaneously.

\item Enable slurm.

	\texttt{sudo systemctl enable slurmctld} \quad \# Control node \\
	\texttt{sudo systemctl enable slurmd} \quad \# Compute nodes 
	
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\

\section{Database setup} \label{sec:slurmDB}

\begin{enumerate}

\item If you followed the basic slurm install instructions in section \ref{sec:basicslurm}, you should have downloaded the MiniClusterTools git repo. If not, do it now.

\texttt{git clone https://github.com/coyleej/MiniClusterTools.git}

\item Run \texttt{slurmdb\_initial\_setup.sh}. It automates much of the setup:

	\texttt{bash slurmdb\_initial\_setup.sh}

	Here's what the script does, with some explanation:

%%%%%%%% v NEW v %%%%%%%%
	\begin{enumerate}
	\item Create the log file: \\
	\texttt{touch /var/log/slurmdbd.log} \\
	\texttt{chown slurm: /var/log/slurmdbd.log}

	\item Create the pid file: \\
	\texttt{touch /var/run/slurm-llnl/slurmdbd.pid} \\
	\texttt{chown slurm: /var/run/slurm-llnl/slurmdbd.pid}

	\item In \texttt{slurm.conf}, make the following changes:

		\begin{enumerate}
		\item Uncomment: \\
		\texttt{JobAcctGatherType=jobacct\_gather/linux} \\
		\texttt{JobAcctGatherFrequency=30} \\
		\texttt{AccountingStorageType=accounting\_storage/slurmdbd}

		\item Modify: \\
%		\texttt{AccountingStorageLoc=slurm\_acct\_db} \\
%		\texttt{AccountingStoragePass} \\
		\texttt{AccountingStorageHost=<IP or domain name>} \\
		\texttt{AccountingStorageLoc=/var/lib/mysql} \\
		\texttt{AccountingStoragePass=/var/run/munge/munge.socket.2}   \quad \# munge daemon port \\
		\texttt{AccountingStoragePort=3306} \\
		\texttt{AccountingStorageUser=slurm}

		\item Add: \\
		\texttt{AccountingStoreJobComment=YES} \\
%		%Setting AccountingStorageEnforce requires a RESTART of slurmctld
		\texttt{AccountingStorageEnforce=associations} \\
		\texttt{AccountingStorageTRES=gres/gpu,gres/gpu:gtx1080ti}	\quad \# \href{https://slurm.schedmd.com/tres.html}{by default billing, CPU, energy, and node are tracked}
		\end{enumerate}
	
	\item Restart \texttt{slurmctld}, as required by some of these changes: \\ %\texttt{AccountingStorageEnforce} 
	\texttt{systemctl restart slurmctld}

	\item Copy \texttt{slurmdbd.conf.example} to \texttt{slurmdbd.conf}.

	\item Open \texttt{slurmdbd.conf} 

		\begin{enumerate}
		\item Change the following lines to the following:

			\texttt{DbdAddr=<magnetoIP>} \\
			\texttt{DbdHost=magneto} \\
			\texttt{PidFile=/var/run/slurm-llnl/slurmdbd.pid}  %# originally in /var/run/
	
		\item Modify the following:

			\texttt{StorageHost=magneto} \\
			\texttt{StoragePort=3306}  \quad \# the mysql default port \\
			\texttt{StoragePass=<password>}		\quad \# slurm's password in MariaDB
			\texttt{StorageLoc=slurm\_acct\_db}
	
		\item Add the following:

			\texttt{PurgeEventAfter=12months} \\
			\texttt{PurgeJobAfter=12months} \\
			\texttt{PurgeResvAfter=2months} \\
			\texttt{PurgeStepAfter=2months} \\
			\texttt{PurgeSuspendAfter=1month} \\
			\texttt{PurgeTXNAfter=12months} \\
			\texttt{PurgeUsageAfter=12months}
		\end{enumerate}

	\item Re-read the config files: \texttt{scontrol reconfigure}

	\item We need to enable remote access to mariadb. Open \texttt{/etc/mysql/my.cnf} (it's symlinked to \texttt{/etc/mysql/mariadb.cnf}), and append the following to the end of the file:

		\texttt{[mysqld]} \\
		\texttt{skip-networking=0} \\
		\texttt{skip-bind-address}

	\item Start MariaDB: \texttt{systemctl start mariadb}
	\end{enumerate}

%%%%%%%% DATABASE SETUP %%%%%%%%

\item Verify the setup with

	\texttt{scontrol show config | grep AccountingStorageHost}

%https://slurm.schedmd.com/accounting.html#database-configuration
\item Troubleshoot the MariaDB daemon if it didn't start automatically in the script. Follow whatever error messages it gives, then restart the node and try again.

	\texttt{sudo systemctl start mariadb}

If there have been multiple failed connection attempts, you may need to use the following to unblock the host IP: 

	\texttt{sudo mysqladmin flush-hosts}

\item Set up MariaDB:

	\begin{enumerate}
	\item \texttt{sudo mysql\_secure\_installation}
	\item Set up the MariaDB root user password: Y 
	\item Create root password: [redacted]
	\item Remove the anonymous user: Y
	\item Restrict root user access to the local machine: Y
	\item Remove the test database: Y
	\item Reload privilege tables: Y
	\end{enumerate}

\item Log in to the MariaDB server as the root user and add a slurm user. (MariaDB doesn't actually require the capitalization, but I'm including it to match \href{https://mariadb.com/kb/en/library/account-management-sql-commands/}{their documentation}.

	\begin{enumerate}
	\item Open the database: \texttt{sudo mysql} %\texttt{mysql -u root -p}

	\item Create the database:

		\texttt{MariaDB [(none)]> CREATE DATABASE slurm\_acct\_db;}
	
		Confirm with:

		\texttt{MariaDB [(none)]> SHOW DATABASES;}
	
	\item Create a slurm user and grant database access (replace '$<$pass$>$' with the value in \texttt{slurmdbd.conf}):

		\texttt{GRANT ALL ON slurm\_acct\_db.* TO 'slurm'@'\%' IDENTIFIED BY '<pass>' with grant option;}
	
		Confirm with:

		\texttt{MariaDB [(none)]> SELECT user, host, plugin FROM mysql.user;} \\
		\texttt{MariaDB [(none)]> SHOW GRANTS for slurm@localhost;}

	\item Review the current setting for MySQL's \texttt{innodb\_buffer\_pool\_size} before running the slurmdbd for the first time.

		\texttt{MariaDB [(none)]> SHOW VARIABLES LIKE innodb\_buffer\_pool\_size;}

	\item Consider setting this value large enough to handle the size of the database. This helps when converting large tables over to the new database schema and when purging old records. Setting \texttt{innodb\_lock\_wait\_timeout} and \texttt{innodb\_log\_file\_size} to larger values than the default is also recommended. Note: The default buffer size is 128M.

		These variables can be changed in one of the following files (not sure which one, but I suspect it's the first one):

		\texttt{/etc/mysql/conf.d/mysql.cnf} \\
		\texttt{/etc/mysql/mariadb.cnf} \\
		\texttt{/etc/mysql/mariadb.conf.d/*.cnf}

		\begin{verbatim}
		[mysqld]
		innodb_buffer_pool_size=256M
		innodb_log_file_size=256M
		innodb_lock_wait_timeout=1800
		\end{verbatim}

		To implement this change you must shut down the database and move/remove the log files:

		\begin{verbatim}
		sudo systemctl stop mariadb
		sudo rm /var/lib/mysql/ib_logfile?
		sudo systemctl start mariadb
		\end{verbatim}

		Verify the new buffer setting using the following command in the MariaDB shell:

		\texttt{MariaDB [(none)]> SHOW VARIABLES LIKE innodb\_buffer\_pool\_size;}

		This has been left as the default for now (obviously).

	\item Exit MariaDB:

		\texttt{MariaDB [(none)]> QUIT;}
	\end{enumerate}

\item Start \texttt{slurmdbd}, acting on any issues that may appear:

	\texttt{sudo systemctl start slurmdbd}

	One issue I encountered was fixed by manually changing the owner of the database directory, and reinstall mariadb:
	
	\texttt{sudo chown mysql: /var/lib/mysql} \\
	\texttt{sudo apt install --reinstall mariadb-common mariadb-client mariadb-server}
	
	Try setting up the database again.

	If it's still grumpy, install \texttt{mysql-server-5.7} with \texttt{apt}, then try setting up the database again.

\item Enable \texttt{mariadb} and \texttt{slurmdbd}.

%%%%%%%% ACCOUNTING SETUP %%%%%%%%

\item For job accounting to work, the database and accounting tools must be configured as explained in \href{https://slurm.schedmd.com/accounting.html#database-configuration}{the official documentation}. Use \texttt{sacctmgr} to create and manage these records.

Accounting records are maintained based on ``associations" consisting of four elements: cluster, account, user names and an optional partition name. All accounting things are lower case. \emph{You must define clusters before you add accounts and you must add accounts before you add users.}
%\url{https://wiki.fysik.dtu.dk/niflheim/Slurm_accounting}

	\begin{enumerate}
	\item Add the cluster to the database: \\
		\texttt{sacctmgr add cluster <clustername>}

	\item Add accounts: \\	
		\texttt{sacctmgr add account <account> [Cluster=<clustername>] [parent=<parent>] \textbackslash{}}\\ 
		\texttt{Description="<description>" Organization=<organization>} \\
		Omitting \texttt{Cluster} will add the account to all clusters. \texttt{parent} is only required if the new account is a sub-account of another account. \\


	\item Add users: 

		\texttt{sacctmgr add user <username> [Account=<accounts>] [DefaultAccount=<account>]}

%		Is it \texttt{sacctmgr add user <username>} or \texttt{sacctmgr add user name=<username>}?

		\texttt{Account} can take a single account or a comma separated list. Not specifying \texttt{Account} will give the user access to all accounts on the cluster. \texttt{DefaultAccount} will set the default account for a user. At least one of the two options is required.


	\item Commands to view accounting information:

		\texttt{sacctmgr list cluster} \\
		\texttt{sacctmgr list configuration} \\
		\texttt{sacctmgr list stats}
	
	\end{enumerate}

%%%%%%%% v NEW v %%%%%%%%
\item If other nodes than the \texttt{slurmdbd} node must be able to connect to the \texttt{slurmdbd} service, you must open the firewall to specific hosts. Please see the \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration}{Slurm\_configuration} page under the firewall section.

\item Make the following changes in \texttt{slurmdbd.conf}:

	May want to set \texttt{PrivateData}

\item Currently have no need to set up WCkeys. (\href{https://slurm.schedmd.com/wckey.html}{Workload characterization keys} are an orthogonal way to do accounting against possibly unrelated accounts. This can be useful where users from different accounts are all working on the same project.)

\item \href{https://slurm.schedmd.com/qos.html}{QOS} includes multifactor job priority and job preemption. View with \texttt{sacctmgr}. By default everything is assigned normal. Can create something with higher priority.

\item Job completion logging is redundant if using the accounting infrastructure.
%%%%%%%% ^ NEW ^ %%%%%%%%

%%%%%%%% PAM MODULE SETUP %%%%%%%%
\item Don't set up PAM with the configuration we currently have! As long as users must submit from the node they want to run on, this is counterproductive!! For future use, see \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#pam-module-restrictions}{this guide}.

%%%%%%%% START SLURM %%%%%%%%
\item Enable and start all daemons: \texttt{mariadb}, \texttt{slurmdbd}, \texttt{slurmctld}, \texttt{slurmd}

\item If you wish to customize \texttt{squeue} output, refer to section \ref{sec:customsqueue}

\end{enumerate}

%
%\section{MariaDB setup on new database host} \label{sec:movemariadb}
%
%\begin{enumerate}
%\item Find the current database directory. It should report back the default (\texttt{/var/lib/mysql}): \\
%\texttt{sudo mysql -e "SELECT @@datadir;"}
%
%\item Stop the database daemons to avoid data corruption: \\
%\texttt{sudo systemctl stop slurmdbd} \\
%\texttt{sudo systemctl stop mariadb} \\
%\texttt{sudo systemctl is-active mariadb}
%
%\item Create the new directory and change it's owner to \texttt{mysql}: \\
%\texttt{sudo mkdir /srv/mariadb-data} \\
%\texttt{sudo chown mysql: /srv/mariadb-data} 
%
%\item Recursively copy the data to the new location: \\
%\texttt{sudo cp -R -p /var/lib/mysql/* /srv/mariadb-data}
%
%\item Back up the original configuration files: \\
%\texttt{cd /etc/mysql} \\
%\texttt{sudo cp mysql.cnf mysql.cnf.backup} \\
%\texttt{sudo cp debian.cnf debian.cnf.backup} \\
%\texttt{sudo cp debian.cnf-5.7 debian.cnf-5.7.backup} \\
%\texttt{cd /etc/mysql/mariadb.conf.d} \\
%\texttt{sudo cp 50-server.cnf 50-server.cnf.backup} \\
%\texttt{sudo cp 50-client.cnf 50-client.cnf.backup}
%
%\item Configure all the things: (\href{https://www.tecmint.com/change-default-mysql-mariadb-data-directory-in-linux/}{original source})
%
%In \texttt{/etc/mysql}, replace \texttt{mysql.conf.d} with \texttt{mariadb.conf.d}.
%
%In \texttt{/etc/mysql/debian.cnf-5.7}, replace both instances of \texttt{socket=\dots} with: \\
%\texttt{socket=/srv/mariadb-data/mysql.sock}
%
%In \texttt{/etc/mysql/debian.cnf}, replace both instances of \texttt{socket=\dots} with: \\
%\texttt{socket=/srv/mariadb-data/mysql.sock}
%
%In \texttt{/etc/mysql/mariadb.conf.d/50-client.cnf}, change the following under \texttt{[mysql]}: \\
%\texttt{socket=/srv/mariadb-data/mysql.sock} \\
%\texttt{port=3306} \texttt{\# new line}
%
%In \texttt{/etc/mysql/mariadb.conf.d/50-server.cnf}, change the following under \texttt{[mysqld]}: \\
%\texttt{socket=/srv/mariadb-data/mysql.sock} \\
%\texttt{pid-file=/srv/mariadb-data/mysql.pid} \\
%\texttt{datadir=/srv/mariadb-data}
%
%\item Start \texttt{mariadb} and check its status.
%\texttt{sudo systemctl daemon-reload} \\
%\texttt{sudo systemctl start mariadb} \\
%\texttt{sudo systemctl status mariadb}
%
%\item Double check that the database directory has been updated: \\
%\texttt{sudo mysql -e "SELECT @@datadir;"}
%
%\item Start \texttt{slurmdbd} and check it's status.
%
%\end{enumerate}

\section{Slurm plugins} \label{sec:slurmplugins}

Do not change the default Slurm plugin location in \texttt{slurm.conf}!

Default location: \texttt{/usr/lib/x86\_64-linux-gnu/slurm-wlm}

\subsection{Node health check}

\section{Slurm admin commands} \label{sec:slurmadmin}
These are the most common admin-specific commands \emph{in addition to the ones listed in section \ref{sec:queuecommands}}. (Those commands can be run with \texttt{sudo} to affect \emph{any} job.) For details, refer to \texttt{man <command>}.

\begin{itemize}
\item Setup and rebooting commands \\
\addcontentsline{lot}{table}{Slurm setup and management}
\begin{tabular}{l p{3.4in}}
\texttt{scontrol reboot [ASAP] [Nodelist]} & Reboots nodes, see documentation \\
\texttt{scontrol shutdown} & Shuts down the slurm daemons \\
\texttt{sacctmgr shutdown} & Shuts down the cluster \\
\texttt{slurmd -C} & Displays the physical configuration of a node when run on that specific node \\
\texttt{scontrol reconfigure} & Makes running daemons re-read configuration files \\
\end{tabular}

\item Selected management and accounting commands \\
\addcontentsline{lot}{table}{Slurm management and accounting commands}
\begin{tabular}{l p{3.4in}}
\texttt{sacct [options]} & Display accounting information for slurm jobs \\
\texttt{sacctmgr} & View and modify slurm account info \\
\texttt{sacctmgr add <entity> <specs>} & Add cluster, accounts, users; identical to \texttt{create} \\
\texttt{sacctmgr list <entity> [specs]} & Displays information about the specified entity\\
\texttt{sdiag} & Scheduling diagnostic tool \\
\texttt{smd} & Failure management suport tool \\
\texttt{sreport [options] [command]} & Generates reports of job usage and cluster utilization \\
\texttt{sstat} & Display various status information \\
\texttt{sview} & Graphical user interface to view and modify slurm \\
\end{tabular}

%\item User management commands (beyond commands in the previous section)\\
%\addcontentsline{lot}{table}{Slurm user management}
%\begin{tabular}{l p{3.4in}}
%squeue -ho %A -t R | xargs -n 1 scontrol suspend
%squeue -o "%.18A %.18t" -u <username> | awk '{if ($2 =="S"){print $1}}' | xargs -n 1 scontrol resume
%squeue -ho %A -u $USER -t S | wc -l
%lsload |grep 'Hostname\|<partition>'
%\end{tabular}

\item Daemon commands: \texttt{slurmctld}, \texttt{slurmd}, and \texttt{slurmdbd} are the master/control, compute, and database daemons, respectively. They may need to be restarted if configuration files are modified (section \ref{sec:slurmconfig}). \\
\addcontentsline{lot}{table}{Slurm daemons}
\begin{tabular}{l p{3.8in}}
\texttt{systemctld enable <daemon>} & Enable daemons to start on boot; will not start a stopped daemon \\
\texttt{systemctld disable <daemon>} & Disable daemon so that it will not start; will not stop a running daemon \\
\texttt{systemctld start <daemon>} & Starts daemon manually, does not enable the daemon \\
\texttt{systemctld stop <daemon>} & Stops daemon manually, does not disable the daemon \\
\texttt{systemctld status <daemon>} & Reports status of daemon \\
\texttt{<daemon> -Dvvvv} & Manually starts the daemon; ``D" runs in the foreground and ``v"s (can have 0 to 7 ``v"s) indicates desired verbosity \\
\end{tabular}

\end{itemize}

\section{Adjusting configuration files} \label{sec:slurmconfig}

When changing configuration files (e.g.\ \texttt{slurm.conf}, \texttt{cgroup.conf}), the change must first be distributed to all compute and login nodes. After copying the new configuration files to all nodes, use \texttt{scontrol reconfigure} on the control node to force all slurm daemons to re-read the configuration file. The slurm controller (\texttt{slurmctld}) forwards the request to all other daemons (e.g.\ \texttt{slurmd}). Depending on the changes, you may also have to restart the slurm daemons. From the \texttt{scontrol} man page about the reconfigure option:

\begin{enumerate}
\item If you modify settings like Epilog, Prolog, SlurmctldLogFile, SlurmdLogFile, etc.), all you need to do is run \texttt{scontrol reconfigure}. Running jobs will continue execution.
\item Slurm daemons \emph{must be restarted} if any of these parameters are changed: AccountingStorageEnforce, AuthType, BackupAddr, BackupController, ControlAddr, ControlMach, PluginDir, StateSaveLocation, SlurmctldPort, SlurmdPort.
\item Slurm daemons \emph{must be restarted} if nodes are added to or removed from the cluster.
\end{enumerate}

\texttt{ControlMachine} and \texttt{ControlAddr} are defunct in newer versions; use \texttt{SlurmctldHost} instead.

\subsection{Adding/removing nodes} \label{subsec:addnodes}

When adding/removing nodes, do the following:
\begin{enumerate}
\item Stop \texttt{slurmctld}
\item Add/remove nodes in \texttt{slurm.conf}
\item Restart \texttt{slurmd} on all nodes
\item Start \texttt{slurmctld}
\end{enumerate}

\noindent It is also possible to add nodes to \texttt{slurm.conf} with \texttt{state=FUTURE}. The nodes will not be seen by slurm commands in this state. Make them available by changing their state in the \texttt{slurm.conf} file and update the node state using \texttt{scontrol} rather than restarting the \texttt{slurmctld} daemon.

\section{Reboot and shutdown nodes} \label{sec:slurmpowercycle}

\subsection{Reboot} \label{subsec:slurmreboot}

Nodes may need to be rebooted after firmware or kernel upgrades. Reboot them as they become idle using the \texttt{RebootProgram} as configured in \texttt{slurm.conf}. Be mindful of slurm downtime behavior (section \ref{subsec:slurmdowntime}).

\begin{verbatim}
scontrol reboot [ASAP] [NodeList]              # comma-separated, slurm 17.11.2
scontrol reboot [ASAP] [nextstate=<RESUME|DOWN>] [reason=<reason>] [NodeList]  # newer
\end{verbatim}

Explanation: \texttt{ASAP} will prevent initiation of new jobs, otherwise the system will wait until it is idle to reboot. Job scheduling is still allowed. Node state will be REBOOT until rebooted or the reboot is cancelled. NOTE: Behavior of \texttt{ASAP} is sometime wonky in slurm 17.11.2.

Newer versions of slurm also include \texttt{nextstate}, which specifies the state of the node after reboot, and \texttt{reason}, shows users the reason the node is unavailable.

To cancel a reboot, use one of the following

\begin{verbatim}
scontrol update NodeName=<nodename> State=RESUME # slurm version 17.11.2
scontrol cancel_reboot <nodelist>                # more recent versions, e.g. 18.08
\end{verbatim}

\subsection{Shutdown} \label{subsec:slurmshutdown}

Shut down slurm daemons with \texttt{scontrol shutdown [options]}, and servers with \texttt{sacctmgr shutdown}.

\subsection{Slurm downtime behavior} \label{subsec:slurmdowntime}
Be mindful of your configured SlurmdTimeout and SlurmctldTimeout values. If the Slurm daemons are down for longer than the specified timeout (currently 5 minutes) during an upgrade, nodes may be marked DOWN and their jobs killed. You can either increase the timeout values during an upgrade or ensure that the slurmd daemons on compute nodes are not down for longer than SlurmdTimeout. 

\section{Backup and restore database} \label{sec:slurmDBbackup}

\href{https://wiki.fysik.dtu.dk/niflheim/Slurm_database#backup-and-restore-of-database}{(source for the following)}

In order to backup the entire database to a different location (for disaster recovery or migration), the following files must be backed up. Make a database mysqldump using this script /root/mysqlbackup (insert the correct root database password for PWD):
\begin{verbatim}
#!/bin/sh
# MySQL Backup Script for All Databases
HOST=localhost
BACKUPFILE=/root/mysql_dump
USER=root
PWD='**********'
DUMP_ARGS="--opt --flush-logs --quote-names"
DATABASES="--all-databases"
/usr/bin/mysqldump --host=$HOST --user=$USER --password=$PWD $DUMP_ARGS \
     --result-file=$BACKUPFILE $DATABASES
\end{verbatim}

Write permission to \$BACKUPFILE is required.

Make regular database dumps, for example by a crontab job:
\texttt{30 7 * * * /root/mysqlbackup}

Restore of a database backup: The database contents must be loaded from the backup. To restore a MySQL database see for example \href{http://stackoverflow.com/questions/105776/how-do-i-restore-a-mysql-dump-file}{How do I restore a MySQL .dump file?}. As user root input the above created backup file:

\texttt{mysql -u root -p < /root/mysql\_dump}

\section{Upgrading slurm} \label{sec:slurmupgrade}

Almost every new major release of Slurm (e.g. 16.05.x to 17.02.x) involves changes to the state files with new data structures, new options, etc. Slurm permits upgrades between any two versions whose major release numbers differ by two or less (e.g. 16.05.x or 17.02.x to 17.11.x) without loss of jobs or other state information. State information from older versions will not be recognized and will be discarded, resulting in loss of all running and pending jobs. State files are not recognized when downgrading and will be discarded. Create backup copies of state files before proceeding to later recover the jobs.

\texttt{slurmdbd} must be the same or higher major release as \texttt{slurmctld}. When changing the version to a higher release number (e.g.\ from 16.05.x to 17.02.x) \emph{always} upgrade \texttt{slurmdbd} first. Database table changes may be required for the upgrade. If the database contains a large number of entries, \texttt{slurmdbd} may require an hour or two to update the database and will be unresponsive during this time.

\texttt{slurmctld} must be upgraded before or at the same time as \texttt{slurmd} on the compute nodes. It is recommended to update all daemons at the same time.

The libslurm.so version is increased every major release. Packages with slurm integration (e.g.\ MPI libraries) should be recompiled. Sometimes symlinking old \texttt{.so} name(s) to the new one(s) may work, but this is not guaranteed.

If you built your own version of Slurm plugins, they will likely need modification to support a new version of Slurm. It is common for plugins to add new functions and function arguments during major updates. See the RELEASE\_NOTES file for details.

The recommended upgrade order is as follows:

        \begin{enumerate}
        \item Shutdown the slurmdbd daemon
        \item Dump the Slurm database using \texttt{mysqldump} in case of possible failure
        \item Increase \texttt{innodb\_buffer\_size} in \texttt{my.cnf} to 128M
        \item Upgrade the slurmdbd daemon
        \item Restart the slurmdbd daemon
        \item Increase SlurmdTimeout and SlurmctldTimeout values and \texttt{scontrol reconfigure} to take effect
        \item Shutdown the slurmctld daemon(s)
        \item Shutdown the slurmd daemons on the compute nodes
        \item Copy the contents of the configured StateSaveLocation directory in case of possible failure
        \item Upgrade the slurmctld and slurmd daemons
        \item Restart the slurmd daemons on the compute nodes
        \item Restart the slurmctld daemon(s)
        \item Validate proper operation
        \item Restore original SlurmdTimeout and SlurmctldTimeout, and then \texttt{scontrol reconfigure}
        \item Destroy backup copies of database and/or state files
        \end{enumerate}

Note: It is possible to update the slurmd daemons on a node-by-node basis after the slurmctld daemon(s) are upgraded, but make sure their down time is below the SlurmdTimeout value.
