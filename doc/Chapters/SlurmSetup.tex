\chapter{Slurm installation and setup} \label{ch:slurmsetup}

\textbf{\emph{This setup works on Ubuntu 18.04 and Ubuntu Server 18.04.}}

SchedMD recommends a separate database server if possible. It may be on the same server as \texttt{slurmctld}, but this may impact performance. You should consider optimizing the database performance by mounting the MariaDB or MySQL database directory on a dedicated high-speed file system. Ideally this would be a PCIe SSD disk drive (e.g.\ Intel SSD P3700 series or Kingston E1000 series), but SSD SAS/SATA will also work. Drives must be qualified for high-volume random small read/write operations, and should be built with the Non-Volatile Memory Express (NVMe) storage interface standard for reliability and performance. A disk size of 200 GB or 400 GB should be sufficient. Consider installing 2 disk drives in a RAID-1 configuration.

The following will be installed in this setup guide:

\begin{itemize}
\item MPI : OpenMPI version 2
\item Slurm 17.11.2-1
\item Authentication and digital signatures: MUNGE
\item Database : MariaDB
\end{itemize}

\section{Reference materials} \label{sec:slurmguides}

This guide was constructed from the following references and my own experiences:

\href{https://slurm.schedmd.com/quickstart_admin.html}{Slurm admin quick-start} \\
\indent \href{https://slurm.schedmd.com/documentation.html}{Slurm official documentation} \\
\indent \texttt{man slurm-wlm-doc} for Slurm 17.11.2-1build1 \\
\indent \href{https://slurm.schedmd.com/man_index.html}{Slurm man pages and configuration file index} \\
\indent \href{https://slurm.schedmd.com/mc_support.html}{Slurm multi-core support} \\
\indent \href{https://slurm.schedmd.com/download.html}{Slurm download and addons list} \\
\indent \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration}{Slurm configuration (Niflheim)} \\
\indent \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_database}{Slurm database (Niflheim)} \\
\indent \href{https://github.com/dholt/slurm-gpu}{Slurm-gpu github}

\section{Note on hyperthreading} \label{sec:slurmHT}

%Check for hyperthreading on your system with \texttt{lscpu} or \texttt{lscpu | grep "per core"}.

From the \href{https://slurm.schedmd.com/faq.html}{slurm documentation} on hyperthreading:
	\begin{quotation}
	If your nodes are configured with hyperthreading, then a CPU is equivalent to a hyperthread. Otherwise a CPU is equivalent to a core. You can determine if your nodes have more than one thread per core using the command ``scontrol show node" and looking at the values of ``ThreadsPerCore".

	Note that even on systems with hyperthreading enabled, the resources will generally be allocated to jobs at the level of a core (see NOTE below). Two different jobs will not share a core except through the use of a partition OverSubscribe configuration parameter. For example, a job requesting resources for three tasks on a node with ThreadsPerCore=2 will be allocated two full cores. Note that Slurm commands contain a multitude of options to control resource allocation with respect to base boards, sockets, cores and threads.

	(NOTE: An exception to this would be if the system administrator configured SelectTypeParameters=CR\_CPU and each node's CPU count without its socket/core/thread specification. In that case, each thread would be independently scheduled as a CPU. This is not a typical configuration.)
	\end{quotation}

If \texttt{SelectTypeParameters} is set to \texttt{CR\_CPU} or \texttt{CP\_CPU\_Memory}, slurm will treat each thread as a CPU and completely disregard which core a thread is on. If it is set to \texttt{CR\_Core} or \texttt{CR\_Core\_Memory}, slurm can assign multiple threads to a core but will not assign multiple jobs to the same core. If it is set to \texttt{CR\_ONE\_TASK\_PER\_CORE}, slurm assigns one task per core regardless of the number of threads available. 

%You can also disable hyperthreading in the kernel using \texttt{grub}:
%
%\begin{enumerate}
%\item Create a backup copy of \texttt{/etc/default/grub}.
%
%\item Open \texttt{/etc/default/grub} and set the maximum number of CPUs the the number of physical cores:
%
%	Find the line that begins with \texttt{GRUB\_CMDLINE\_LINUX\_DEFAULT=}. Append \texttt{maxcpus=N} after other options like \texttt{quiet splash}
%
%\item Save the file, then run \texttt{sudo update-grub}
%
%\item Reboot, then check for hyperthreading with \texttt{lscpu | grep "per core"}.
%\end{enumerate}

\section{Basic Slurm set up} \label{sec:basicslurm}

\begin{enumerate}
\item If you intend to set up a database on its own high speed drive, mount the drive now. % Default database location is /var/lib/mysql

%%%%%%%% INSTALL REQUIRED PACKAGES %%%%%%%%
\item Make sure that OpenMPI is installed. If not, install it with

	\texttt{sudo apt install libopenmpi2 libopenmpi-dev openmpi-common openmpi-doc}

\item Download the \href{https://github.com/coyleej/MiniClusterTools}{MiniClusterTools repo}  if you haven't already. It contains a slurm installation script.

	\texttt{git clone https://github.com/coyleej/MiniClusterTools.git}

%%%%%%%% BASH SCRIPT %%%%%%%%
\item Run \texttt{install\_slurm.sh}. It automates much of the setup. The following explains what it does.

	\texttt{bash install\_slurm.sh}

	\begin{enumerate}
	\item Set five variables for the cluster name, controller information, and backup controller. If there is no backup controller, leave \texttt{backupname="NULL"}. The script will handle this automatically.

	\item Create Munge user with \texttt{uid} and \texttt{gid} of 399. (Can be any \emph{unused} value between SYS\_UID\_MIN and SYS\_UID\_MAX, which are defined in \texttt{/etc/login.defs}). 

		\texttt{mungeUID=399} \\
		\texttt{sudo groupadd -g \$mungeUID munge} \\
		\texttt{sudo useradd -r -u \$mungeUID -g \$mungeUID munge} \\
		\texttt{sudo usermod -d /nonexistent munge}

	\item Make sure the system clock is set to the proper timezone and that your system clock is correct:

		\texttt{sudo timedatectl set-timezone America/New\_York} \\
		\texttt{timedatectl}

	\item Check that \texttt{nvidia-driver-430} or newer is installed so that slurm can find the GPUs.

		\begin{enumerate}
		\item Check that we're using the Ubuntu \texttt{graphics-drivers} PPA. If we aren't:

			\texttt{sudo add-apt-repository ppa:graphics-drivers/ppa} \\
			\texttt{sudo apt update}

		\item Use \texttt{apt} to purge anything older than \texttt{nvidia-driver-430}.

		\item Use \texttt{apt} to install \texttt{nvidia-driver-430} if you purged an older driver.

		\end{enumerate}

	\item Install OpenMPI if it is not presently installed:

		\texttt{sudo apt install libopenmpi2 libopenmpi-dev openmpi-common openmpi-doc}

	\item Install MUNGE, SLURM, MySQL, MariaDB, and cgroup-tools: \\
		\texttt{apt install munge libmunge-dev libpam-slurm slurmd slurmdbd slurm-wlm-doc \\ cgroup-tools mariadb-common mariadb-server} % mysql-common mysql-server}

	\item If the node in question is the control node or the backup control node:

		\texttt{sudo apt install slurmctld slurm-wlm slurmdbd}

		Otherwise:

		\texttt{sudo apt install slurm-client} 

	\item User prompts will gather some information on GPUs.

%%%%%%%% CONTROL NODE CONFIGURATION %%%%%%%%
	\item Configure the control node, if applicable. 

		\begin{enumerate}
		\item Make sure that \texttt{/var/spool/slurmctld/} and \texttt{/var/log/slurm-llnl/} exist. If not, create them with \texttt{mkdir}.

		\item Make sure that slurm is the owner of these directories. If not, use \texttt{chown slurm: <dirname>}.

		\item Make sure that the permissions on these directories are set to \texttt{755}. If not, use \texttt{chmod}.

		\item Check that \texttt{/var/log/slurm-llnl/slurmctld.log} exists and is owned by slurm. Otherwise, create it using \texttt{touch} and \texttt{chown}.

		\item Create the Linux default accounting file.

			\texttt{sudo touch /var/log/slurm-llnl/slurm\_jobacct.log} \\
			\texttt{sudo chown slurm: /var/log/slurm-llnl/slurm\_jobacct.log } \\
			\texttt{sudo touch /var/log/slurm-llnl/slurm\_jobcomp.log} \\
			\texttt{sudo chown slurm: /var/log/slurm-llnl/slurm\_jobcomp.log}

		\end{enumerate}

%%%%%%%% COMPUTE NODE CONFIGURATION %%%%%%%%
	\item Configure the compute nodes. See \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#id12}{this site} for further details. 

		\begin{enumerate}
		\item Create the \texttt{slurmd} spool directory with the correct ownership.

			\texttt{mkdir /var/spool/slurmd} \\% /var/log/slurm} \\
			\texttt{chown slurm: /var/spool/slurmd} \\%  /var/log/slurm} \\
			\texttt{chmod 755 /var/spool/slurmd}% /var/log/slurm} 

		\item Create the log files:

			\texttt{touch /var/log/slurmd.log} \\
			\texttt{chown slurm: /var/log/slurmd.log}
	
		\item Create the pid files (only need \texttt{slurmctld.pid} on the control node):

			\texttt{touch /var/log/slurm-llnl/slurmd.pid /var/log/slurm-llnl/slurmctld.pid} \\
			\texttt{chown slurm: /var/log/slurm-llnl/slurmd.pid /var/log/slurm-llnl/slurmctld.pid}

		\item View the physical configuration (sockets, cores, real memory, etc.) of each of the compute nodes with the command \texttt{slurmd -C}, and update this information in \texttt{slurm.conf}.

		\item Set the \texttt{State} of the node as UNKNOWN (slurm assigns BUSY or IDLE) or FUTURE.

		\item It may be a good idea to assign weights to the compute nodes. All things being equal, jobs will be allocated the nodes with the lowest weight. The enables prioritization based upon hardware parameters such as GPUs, RAM, CPU clock speed, CPU core number, CPU generation. (\href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#node-weight}{more info})

		\item It may be a good idea in the future to uncomment \texttt{TmpFS=} in \texttt{slurm.conf}. (\texttt{/tmp} is the default; can change to e.g.\ \texttt{/scratch}.) You can add \texttt{TmpDisk=xxxxx} to each compute node line, where \texttt{xxxxx} is the size of the temporary file system.

		\end{enumerate}

%%%%%%%% MORE SPOOL! %%%%%%%%
	\item Create spool directories:
	
	\texttt{mkdir -p /var/spool/slurm/d} \\
	\texttt{mkdir /var/spool/slurm/ctld} \\
	\texttt{chown slurm: /var/spool/slurm /var/spool/slurm/d /var/spool/slurm/ctld}
	
%%%%%%%% GRES.CONF %%%%%%%%
	\item Create a \texttt{gres.conf} file. 

	Inside this file, add a line for each GPU available on that node as follows: \texttt{Name=gpu Type=<type> File=/dev/nvidia\#}. (Confirm numbers with \texttt{ls -l /dev/nvidia*}.) See \href{https://slurm.schedmd.com/gres.conf.html}{the documentation} for more options.

%%%%%%%% CGROUP.CONF %%%%%%%%
	\item Copy \texttt{cgroup.conf.example} into \texttt{cgroup.conf} and make the following changes:

		\begin{enumerate}
		\item \texttt{ConstrainCores=no}
		\item \texttt{ConstrainRAMSpace=yes} (change from no)
		\item You may also want to include \texttt{MemSpecLimit} and \texttt{ContrainKmemSpace}.  (\href{https://www.mankier.com/5/cgroup.conf}{reference material})
		\end{enumerate}
		
	\item Adjust the grub configuration. Open \texttt{/etc/default/grub} 
	
	Add \texttt{cgroup\_enable=memory swapaccount=1} to  \texttt{GRUB\_CMDLINE\_LINUX} line.
	
	Run \texttt{update-grub}.

	\item Check the node configuration as detected by slurm by typing \texttt{slurmd -C} into the command line. Adjust the appropriate line of the COMPUTE NODES section of the \texttt{slurm.conf} file to match.

	\item Retrieve the configuration files:

		\begin{enumerate}
		\item Determine your version of slurm by typing \texttt{dpkg -l | grep slurm}. It should report version 17.11.2-1build1. 
	
		\item Obtain the code directly from the command line with: \\ 
	\texttt{wget https://github.com/SchedMD/slurm/archive/slurm-17-11-2-1.tar.gz}
	 
		\item Extract the files. The example configuration files are in \texttt{<unzipped-slurm>/etc/}. Copy all example config files into \texttt{/etc/slurm-llnl/}
	\end{enumerate}

%%%%%%%% SLURM.CONF %%%%%%%%
	\item Copy \texttt{slurm.conf.example} to \texttt{slurm.conf} and change the following. With \texttt{install\_slurm.sh}, the backup controller information is not modified if \texttt{backupname = "NULL"} (the original setting).

		\begin{enumerate}
		\item \texttt{ClusterName=Marvel}

		\item \texttt{ControlMachine=<name>}

		\item \texttt{ControlAddr=<IP>}

		\item \texttt{BackupController=<name>}

		\item \texttt{BackupAddr=<IP>}

		\item \texttt{ProctrackType=proctrack/cgroup}	

		\item \texttt{TaskPlugin=task/cgroup}

		\item \texttt{InactiveLimit=600}	

		\item \texttt{NodeName=thanos}

		\item \texttt{Nodes=thanos}

		\item \texttt{PartitionName=CEM}

		\item Remove \texttt{Procs=1} and replace it with \texttt{CPUs=128}. (On a multi-core/hyperthreaded system, slurm uses the number of threads as the number of CPUs)

		\item Add a RESOURCES section just above COMPUTE NODES with the following: \texttt{GresTypes=gpu}.

		\item Also under the RESOURCES section, add \texttt{LaunchParameters=send\_gids}. This has \texttt{slurmctld} look up the user name and group ids instead of the individual nodes and prevents the ``couldn't chdir" error. This is the default setting in newer versions of slurm.

		\item In the COMPUTE NODES, add the following to each node containing one or more GPUs. \# is the number of available GPUs on that node: \texttt{Gres=gpu:\#}. Insert this just before \texttt{State=UNKNOWN}.

		\item In the SCHEDULING section, set the default memory per node at 1000 MB. (Slurm's default is ALL, which will not allow multiple jobs simultaneously.) \\
		DefMemPerNode=1000

		\item Change the location of the slurm PID files to the following:

		\texttt{SlurmctldPidFile=/var/run/slurm-llnl/slurmctld.pid} \\ %# originally in /var/run/
		\texttt{SlurmdPidFile=/var/run/slurm-llnl/slurmd.pid} % # originally in /var/run/

		\item Modify \texttt{slurm.conf} so that the nodes can be rebooted while slurm is running. Change the reboot program to \texttt{RebootProgram="/sbin/reboot"}. 

		\item Change when a DOWN node will be returned to service. The default (\texttt{0}) is that nodes will remain down until the admin manually changes the state. We will change this to \texttt{1}, meaning that the nodes will be restored to service if it is reponding, has a valid configuration, and was not manually set as DOWN. \\
		\texttt{ReturnToService=1}

		\item Check that \texttt{StateSaveLocation=/var/spool/slurm/ctld}. This directory should already exist, but doublecheck to make sure.

%%%%%%%% RESOURCES SETTINGS %%%%%%%%
		\item Check that \texttt{FastSchedule=1} and \texttt{SchedulerType=sched/backfill} (default settings).
	
		\item Set the consumable resources (\href{https://slurm.schedmd.com/cons_res.html}{1} and \href{https://slurm.schedmd.com/cons_res_share.html}{2}):
		\texttt{SelectType=select/cons\_res}
	
		\item You must also select what is allowed as consumable resources. In \texttt{slurm.conf}, set \\
		\texttt{SelectTypeParameters=CR\_Core\_Memory}. 
	
		NOTE: If you use memory as a consumable resource, you \emph{must} set the \texttt{RealMemory} parameter.
	
		NOTE: If CPUs are a consumable resource, Slurm has no notion of sockets, cores, or threads. On single- and multi-core systems, CPU refers to cores. On a multi-core/hyperthread system CPU refers to threads.
	
		\item Because both CPUs and Memory are consumable resources, you \emph{must} set \texttt{OverSubscribe=NO} to prevent jobs from conflicting with one another. Strange behavior will occur if \texttt{OverSubscribe=YES}, as jobs will conflict with one another. %Also, slurm automatically assigns all memory to a job by default, so the line \texttt{\#SBATCH --mem=X} must be specified if more than one job is to run simultaneously. 

%%%%%%%% PARTITION CONFIGURATION %%%%%%%%
		\item Configure the partitions in \texttt{slurm.conf}, for example: \\
		\texttt{PartitionName=xeon8 Nodes=a[070-080] Default=YES DefaultTime=50:00:00 \\ MaxTime=168:00:00 State=UNKNOWN}

		In the SCHEDULING section of the \texttt{slurm.conf} file, set \texttt{EnforcePartLimits=YES}. This will reject jobs that exceed a partition's size and/or time limits when they're submitted.

		Things to keep in mind for the future (\emph{\textbf{not setting these up}}):
			\begin{itemize}
			\item Partitions may overlap so that some nodes belong to several partitions. 
	
			\item Access to partitions is configured in \texttt{slurm.conf} using AllowAccounts, AllowGroups, or AllowQos.
	
			\item If some partitions (e.g.\ big memory nodes) should have a higher priority, set this in \texttt{slurm.conf} using the multifactor plugin:
			\texttt{PartitionName ... PriorityJobFactor=10} \\
			\texttt{PriorityWeightPartition=1000}
			\end{itemize}

%%%%%%%% LIMIT PROPAGATION %%%%%%%%
		\item By default, slurm propagates all user limits from the submitting node (see \texttt{ulimit -a} to the batch jobs. Configure \texttt{slurm.conf} so that the locked memory limit isn't propagated by uncommenting and setting as follows: \\
		\texttt{PropagateResourceLimitsExcept=MEMLOCK}
	
		(We haven't done the following, but if you have imposed any non-default limits on the login nodes in \texttt{/etc/security/limits.conf} or \texttt{/etc/security/limits.d/*.conf}, you probably want to prohibit these by setting: 
		\texttt{PropagateResourceLimitsExcept=ALL}
	
		See the slurm documentation for available options.)

%%%%%%%% PLUGIN LOCATION %%%%%%%%
		\item Do NOT modify \texttt{\#PluginDir}! Doing so causes slurm to crash. Slurm defaults to: \\
		\texttt{usr/lib/x86\_64-linux-gnu/slurm-wlm}
		\end{enumerate} 

	\item Start \texttt{slurmd} and, if applicable, \texttt{slurmctld}.

	\texttt{sudo systemctl start slurmd} \\
	\texttt{sudo systemctl start slurmctld \quad \# if applicable}

	You will get a warning or error if \texttt{slurmd -C} failed and the code autofilled the laptop values.

	\item Removes the extracted folder. The downloaded compressed folder is left untouched.
	
	\item End of installation script.
	\end{enumerate}
	
%%%%%%%% ADJUSTMENTS FOLLOWING SCRIPT EXECUTION %%%%%%%%
\item Check that the \texttt{NodeName} line matches the output of \texttt{slurmd -C}. If \texttt{slurmd -C} fails to execute properly, \texttt{install\_slurm.sh} autofills with the values for an Oryx Pro.

\item Resolve any errors that popped up when running the installation script.

	\begin{enumerate}
	\item If the daemon(s) failed to start, type \texttt{systemctl status <daemon>}. If slurm can't find nodes or a machine name, fix the \texttt{slurm.conf} and try again. 

	\item If slurm complains that it doesn't have permissions to access a directory, you probably forgot \texttt{sudo} when starting slurm.

	\item If slurm isn't starting because it is missing directories, manually create those directories, set \texttt{slurm} as the owner, and try again.

	\item If slurm claims to be missing any configuration files (\texttt{*.conf}), see if it exists in \texttt{/etc/slurm-llnl} as \texttt{*.conf.example}. If it does, copy it, modify it, and try again. If it doesn't exist, refer to the source code on github for \texttt{your version of slurm} and copy it where it needs to go.

	\item If slurm can't find the GPUs, make sure that the system can see the GPUs and that you have an appropriate Nvidia driver.

	\item If it's still not working, start slurm manually (section \ref{subsec:manualstart}) to see more detailed error messages. 
	\end{enumerate}

\item \emph{At present the script only handles local setup}. 

	\begin{enumerate}
	\item \texttt{slurm.conf} -- Nodes and partitions on remote machines must be added manually. The rest of the file is the same, so all that will be required is copy/pasting the node and partition information. Add \texttt{NodeAddr=<IP>} just after \texttt{NodeName=<name>} to all of the compute nodes.

	\item \emph{Copy the proper munge key} into \texttt{/etc/munge}, then restart the \texttt{munge} and \texttt{slurmd} daemons.
	\end{enumerate}

\item If you installed slurm with \texttt{install\_slurm.sh}, \texttt{cgroup.conf} will be the same on all nodes and all the \texttt{gres.conf} files will be setup appropriately. If you did not use the script, make sure that \texttt{cgroup.conf} is the same on all compute nodes and add \texttt{gres.conf} files as necessary.

\item Restart the node.

%%%%%%%% MUNGE %%%%%%%%
\item Check that munge is setup properly. \label{list:munge}
	\begin{enumerate}
	\item If munge is already running, stop it with \texttt{systemctl stop munge}.

	\item Check that the following files/directories are owned by \texttt{munge} instead of \texttt{root}: \\
	\texttt{/etc/munge}, 
	\texttt{/usr/bin/munge}, 
	\texttt{/usr/sbin/munged}, 
	\texttt{/var/lib/munge}, 
	\texttt{/var/log/munge}, \\
	\texttt{/var/run/munge}

	\item Create a munge key on the control node with \texttt{sudo /usr/sbin/create-munge-key}. (Ubuntu may have already done this for you.) 

	\item On the controller, make sure the munge key (\texttt{munge.key}) is in \texttt{/etc/munge/munge.key} and change the owner to munge.  

	\item Copy the key from the control node to all existing compute nodes: 

		\texttt{sudo scp /etc/munge/munge.key admin@compute-node:/home/<admin>/}

	\item On the compute nodes, move the \texttt{munge.key} into \texttt{/etc/munge}. Make sure that it is owned by \texttt{munge} with file permissions \texttt{400}.

	\item Make sure that munge is enabled and (re)start it on all machines:

		\texttt{sudo systemctl start munge}

	\item Check if munge is running by typing \texttt{systemctl status munge}.

	\item Test munge: \addcontentsline{lot}{table}{Munge test commands}

	    Generate a credential on stdout: \\
	    \texttt{munge -n} \\
	    Check if a credential can be locally decoded: \\
	    \texttt{munge -n | unmunge} \\
	    Check if a credential can be remotely decoded: \\
	    \texttt{munge -n | ssh <admin>@<node> unmunge} \\
	    Run a quick benchmark: \\
	    \texttt{remunge}

	\end{enumerate}

%%%%%%%% START SLURM %%%%%%%%
\item Start slurm. Don't worry about enabling the daemons just yet; that will happen later.

	\texttt{sudo systemctl start slurmctld} \quad \# Control node \\
	\texttt{sudo systemctl start slurmd} \quad \# Compute nodes 

\item Test that the job submission is working. The submission command is \texttt{sbatch <script-name>}. To check the status of the job, type \texttt{squeue}. Output will be written in the same folder as the script. Refer to section \ref{sec:slurmscripts} for an explanation of the SBATCH directives.

The following test script is also available in the MiniClusterTools repository as \texttt{files/test\_sbatch.sh}:
\begin{verbatim}
	#!/bin/bash
	#SBATCH --job-name=example
	#SBATCH --nodes=1
	#SBATCH --ntasks-per-node=1
	#SBATCH --cpus-per-task=1
	#SBATCH --time=10:00
	#SBATCH --mem=10
	#SBATCH --partition=debug
	#SBATCH --output=%x.o%j
	echo "Hello World!"
	sleep 120
\end{verbatim}

Another script, complete with an explanation of the \texttt{SBATCH} directives, can be found in section \ref{subsec:sbatchscript}.

\emph{Note: Test scripts should contain the \emph{\texttt{sleep}} command to keep the job ``running" for a longer time.}

\item Stop the slurm daemons: 

	\texttt{systemd}: \texttt{sudo systemctl stop <daemon>} \\
	Manual start: \texttt{Ctrl-C}

%%%%%%%% PROLOG & EPILOG %%%%%%%%
\item We are using the default Prolog and Epilog scripts. Refer to the \href{https://slurm.schedmd.com/slurm.conf.html}{documentation} if this changes.

\item Restart the node.
	
\item Start slurm and test the queue to confirm that it can run multiple jobs simultaneously.

\item Enable slurm.

	\texttt{sudo systemctl enable slurmctld} \quad \# Control node(s) \\
	\texttt{sudo systemctl enable slurmd} \quad \# Compute nodes 
	
\end{enumerate}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\

\section{Configure the backup controller} \label{sec:backupControllerSetup}

If you have two controllers (primary and backup), both must have access to the slurm state save folder: \texttt{/var/spool/slurm/ctld}. Because of how our system is set up with NFS and to avoid a single point of failure, some \texttt{rsync} and \texttt{ssh} trickery is required to make both controllers share the state save information.

This particular setup is largely driven by permission-related considerations. Automated tasks cannot use \texttt{sudo}, as \texttt{sudo} is interactive. One way around this is to have \texttt{root} run the process, but \texttt{root} login is disabled on all machines for security reasons. The solution was to have \texttt{root} transfer between the slurm directory and the admin account, and the admin user transfer between servers. I tried getting the slurm user (the actual owner of the state folder) to transfer the data directly, but that didn't work.

\subsection{Sharing StateSaveLocation} \label{subsec:shareStateSave}

You need the \texttt{copy\_state.sh} file from the MiniClusterTools repo to copy information locally between the slurm state folder and the admin folder. What it does:

\begin{enumerate}
	\item Checks for the proper input parameters. There must be one or two options specified. The script is called as:

		\texttt{bash /path/to/copy\_state.sh <direction> [sudo]}

	\item Check that the value of \texttt{<direction>} is acceptable. The only accepted inputs for \texttt{<direction>} are \texttt{to\_admin} and \texttt{to\_root}, which transfer data to the admin account and to the proper slurm-owned state folder, respectively. 

	\item Controls whether the code runs with \texttt{sudo} privileges as required if the user calling the script is anyone other than \texttt{root}. Running with \texttt{sudo} privileges is accomplished by assigning to a shell parameter a string of either \texttt{"sudo"} or \texttt{"with\_sudo"}. Assigning any other value (recommend using \texttt{""}) is equivalent to leaving this option empty.

	\item Recursively copy (with \texttt{rsync}) and change file permissions/ownership as necessary, depending on the direction of transfer.
\end{enumerate}

Now set up automatic Slurm state transfer.

\begin{enumerate}
\item Open \texttt{root}'s crontab on both machines with \texttt{sudo crontab -u root -e}.

	Add the following lines to copy to the other machine once an hour (for now, ultimately more frequently). (Slurm writes the state every 5 seconds.) Note: you must use the admin account for \texttt{rsync}. Running \texttt{rsync} from the root crontab with \texttt{sudo [-i] -u <admin> rsync} will be rejected by the remote servers.
	\begin{verbatim}
	0    * * * * bash /home/<local-admin>/Code/MiniClusterTools/copy_state.sh to_admin
	15   * * * * bash /home/<local-admin>/Code/MiniClusterTools/copy_state.sh to_root
	\end{verbatim}

\item If \texttt{ssh} keys are already set up, skip to step \ref{list:sshkeys}. Otherwise, make ssh keys on each machine in the admin account. Modify the key name/location if desired, but \emph{you must leave the passphrase empty}. 

	\texttt{ssh-keygen [-f \textasciitilde /.ssh/<custom\_name>]}

\item Copy the keys to the admin account on the other controller, then test the key.

	\texttt{ssh-copy-id <admin>@<remote>} \\
	\texttt{ssh -i \textasciitilde /.ssh/<local\_id\_rsa> <admin>@<remote>}

\item Test that \texttt{rsync} works over \texttt{ssh} in the admin account.

	\texttt{rsync -a -e "ssh -i \textasciitilde /.ssh/<local\_id\_rsa>" "<randomfile>" "<admin>@<remote>:\textasciitilde /"}

\item \label{list:sshkeys} Modify the admin crontab on each machine to copy to the remote machine once an hour.

	\begin{verbatim}
	20 * * * *  rsync -au --fake-super -e "ssh -i ~/.ssh/<local_key>" \
	       "/home/<local-admin>/slurm_state" "<admin>@<remoteIP>:/home/<admin>/"
	\end{verbatim}

\item There are a couple ways to confirm that it worked. Wait until after the cron job should have run, then do one of the following:
	\begin{itemize}
	\item Check \texttt{/var/log/syslog}
	\item Check the log mailed by \texttt{rsync}
	\item Check the timestamps in the backup controller's slurm state folder
	\end{itemize}

\item Each controller needs to copy the state files from the active controller \emph{before} starting slurm. I've elected to have the local controller grab the files from the remote controller to ensure that it grabs the most recent state. (This may eventually get turned into a daemon that is required before \texttt{slurmctld} can start, but I'm going with the following for now.) 

	\textbf{NOTE:} The following works beautifully on our cluster. When testing on a new cluster, test it on the backup controller! Otherwise you risk killing all jobs should a part of code not work properly.

	\begin{enumerate}
	\item Open the \texttt{\textasciitilde /.bashrc} file on the admin account on each controller.

		Append the following text:
		\begin{verbatim}
		# Slurmctld start if daemon is not running
		if (! systemctl status slurmctld | grep "[Aa]ctive.*[Rr]unning" > /dev/null); then
		    deltat=$(( $(date "+%s") - $(date "+%s" -r /var/spool/slurm/ctld/job_state) ))

		    if (test $deltat -ge 30); then
		        echo "Retrieving updated slurm state"
		        rsync -au --fake-super -e "ssh -i ~/.ssh/id_rsa_<local>" \
		              "/home/<local>/slurm_state" "<remote>@<IP>:/home/<remote>/"

		        echo "Copying files to proper directory"
		        bash ~/Code/MiniClusterTools/copy_state.sh to_root with_sudo
		    else
		        echo "WARNING: Slurmctld not running for unknown reasons!"
		    fi

		    echo "Starting slurmctld..."
		    sudo systemctl start slurmctld
		fi
		\end{verbatim}

	\item Test this script on the backup controller. Stop \texttt{slurmctld}, then source \texttt{\textasciitilde /.bashrc}.	

		If you see \texttt{Starting slurmctld...} and no error messages, then the script works properly. Confirm that the daemon is running with \texttt{systemctl status slurmctld}.

	\item Disable \texttt{slurmctld}. Now the daemon will only start when the admin logs in for the first time, but the slurm state will always be up to date when the system resumes.
	\end{enumerate}

%	%Create a daemon specifically to run \texttt{rsync} as the admin. Place this daemon somewhere in \texttt{/etc/systemd/system}. Make sure that \texttt{User=} and \texttt{Group=} are set to the admin account in the \texttt{[Service]} section of the daemon.
%%
%%	Open the \texttt{slurmctld} daemon:
%%
%%	\texttt{sudo vi /etc/systemd/system/multi-user.target.wants/slurmctld}
%%
%%	Only allow \texttt{slurmctld} to run after the admin \texttt{rsync} daemon has finished by editing the \texttt{slurmctld} daemon's \texttt{After=} line.
%%
%%	Add \texttt{ExecStartPre} statements in order to \texttt{rsync} as \texttt{root}. Note: this may not work because \texttt{ExecStartPre} runs as \texttt{root}.
%%
%%	May have to create a daemon specifically to run \texttt{rsync} as the admin. Place this daemon somewhere in \texttt{/etc/systemd/system}. Make sure that \texttt{User=} and \texttt{Group=} are set to the admin account in the \texttt{[Service]} section of the daemon.

\item Consider switching from \texttt{cron} to the \texttt{systemd} timers to run more frequently.
\end{enumerate}

\subsection{Set up backup controller takeover} \label{subsec:SetupBackupTakeover}

You must set up the state transfer (section \ref{subsec:shareStateSave}) before attempting this section.

You will need the \texttt{transfer\_slurm\_control.sh} file from the MiniClusterTools repo. What it does:

\begin{enumerate}
	\item Uses \texttt{copy\_state.sh} to transfer the state files to the admin account.

	\item Copies files to the other controller using \texttt{rsync} and \texttt{ssh} keys.

	\item Uses the remote machine's version of \texttt{copy\_state.sh} to transfer the state files to the proper directory.

	\item Issues the takeover command, \texttt{sudo scontrol takeover}.

	\item Stops the local control daemon, \texttt{sudo systemctl stop slurmctld}.
\end{enumerate}

\noindent Set up the state transfer and takeover command:

\begin{enumerate}
\item If \texttt{transfer\_slurm\_control.sh} isn't already an executable, make it executable:

	\texttt{sudo chmod +x transfer\_slurm\_state.sh}

\item (Optional) Open the admin's \texttt{.bash\_aliases} (preferred) or \texttt{.bashrc} on both controllers and alias a command that transfers the slurm state immediately prior to issuing the takeover command, then source \texttt{.bashrc}.

	\texttt{alias state\_takeover='/<path>/<to>/MiniClusterTools/transfer\_slurm\_state.sh'}
\end{enumerate}


\section{Database setup} \label{sec:slurmDB}

\begin{enumerate}

  \item If you followed the basic slurm install instructions in section \ref{sec:basicslurm}, you should have downloaded the MiniClusterTools git repo. If not, do it now.

    \texttt{git clone https://github.com/coyleej/MiniClusterTools.git}

  \item Run \texttt{slurmdb\_initial\_setup.sh}. It automates much of the setup:

    \texttt{bash slurmdb\_initial\_setup.sh}

    Here's what the script does, with some explanation:

%%%%%%%% v NEW v %%%%%%%%
    \begin{enumerate}
      \item Create the log file: \\
        \texttt{touch /var/log/slurmdbd.log} \\
        \texttt{chown slurm: /var/log/slurmdbd.log}

      \item Create the pid file: \\
        \texttt{touch /var/run/slurm-llnl/slurmdbd.pid} \\
        \texttt{chown slurm: /var/run/slurm-llnl/slurmdbd.pid}

      \item In \texttt{slurm.conf}, make the following changes:

        \begin{enumerate}
          \item Uncomment: \\
          \texttt{JobAcctGatherType=jobacct\_gather/linux} \\
          \texttt{JobAcctGatherFrequency=30} \\
          \texttt{AccountingStorageType=accounting\_storage/slurmdbd}

          \item Modify: \\
%          \texttt{AccountingStorageLoc=slurm\_acct\_db} \\
%          \texttt{AccountingStoragePass} \\
          \texttt{AccountingStorageHost=<IP or domain name>} \\
          \texttt{AccountingStorageLoc=/var/lib/mysql} \\
          \texttt{AccountingStoragePass=/var/run/munge/munge.socket.2}   \quad \# munge daemon port \\
          \texttt{AccountingStoragePort=3306} \\
          \texttt{AccountingStorageUser=slurm}

          \item Add: \\
          \texttt{AccountingStoreJobComment=YES} \\
%          %Setting AccountingStorageEnforce requires a RESTART of slurmctld
          \texttt{AccountingStorageEnforce=associations} \\
          \texttt{AccountingStorageTRES=gres/gpu,gres/gpu:gtx1080ti}	\quad \# \href{https://slurm.schedmd.com/tres.html}{by default billing, CPU, energy, and node are tracked}
      \end{enumerate}
	
    \item Restart \texttt{slurmctld}, as required by some of these changes: \\ %\texttt{AccountingStorageEnforce} 
    \texttt{systemctl restart slurmctld}

    \item Copy \texttt{slurmdbd.conf.example} to \texttt{slurmdbd.conf}.

    \item Open \texttt{slurmdbd.conf} 

      \begin{enumerate}
        \item Change the following lines to the following:

          \texttt{DbdAddr=<controlIP>} \\
          \texttt{DbdHost=<controlName>} \\
          \texttt{PidFile=/var/run/slurm-llnl/slurmdbd.pid}  %# originally in /var/run/
	
        \item Modify the following:

          \texttt{StorageHost=magneto} \\
          \texttt{StoragePort=3306}  \quad \# the mysql default port \\
          \texttt{StoragePass=<password>}		\quad \# slurm's password in MariaDB
          \texttt{StorageLoc=slurm\_acct\_db}
	
        \item Add the following:

          \texttt{PurgeEventAfter=12months} \\
          \texttt{PurgeJobAfter=12months} \\
          \texttt{PurgeResvAfter=2months} \\
          \texttt{PurgeStepAfter=2months} \\
          \texttt{PurgeSuspendAfter=1month} \\
          \texttt{PurgeTXNAfter=12months} \\
          \texttt{PurgeUsageAfter=12months}
      \end{enumerate}

    \item Re-read the config files: \texttt{scontrol reconfigure}

    \item We need to enable remote access to mariadb. Open \texttt{/etc/mysql/my.cnf} (it's symlinked to \texttt{/etc/mysql/mariadb.cnf}), and append the following to the end of the file:

      \texttt{[mysqld]} \\
      \texttt{skip-networking=0} \\
      \texttt{skip-bind-address}

    \item Start MariaDB: \texttt{systemctl start mariadb}
    \end{enumerate}

%%%%%%%% DATABASE SETUP %%%%%%%%

  \item Verify the setup with

    \texttt{scontrol show config | grep AccountingStorageHost}

%https://slurm.schedmd.com/accounting.html#database-configuration
  \item Troubleshoot the MariaDB daemon if it didn't start automatically in the script. Follow whatever error messages it gives, then restart the node and try again.

    \texttt{sudo systemctl start mariadb}

    If there have been multiple failed connection attempts, you may need to use the following to unblock the host IP: 

    \texttt{sudo mysqladmin flush-hosts}

  \item Set up MariaDB:

    \begin{enumerate}
      \item \texttt{sudo mysql\_secure\_installation}
      \item Set up the MariaDB root user password: Y 
      \item Create root password: [redacted]
      \item Remove the anonymous user: Y
      \item Restrict root user access to the local machine: Y
      \item Remove the test database: Y
      \item Reload privilege tables: Y
    \end{enumerate}

  \item Log in to the MariaDB server as the root user and add a slurm user. (MariaDB doesn't actually require the capitalization, but I'm including it to match \href{https://mariadb.com/kb/en/library/account-management-sql-commands/}{their documentation}.

    \begin{enumerate}
      \item Open the database: \texttt{sudo mysql} %\texttt{mysql -u root -p}

      \item Create the database:

        \texttt{MariaDB [(none)]> CREATE DATABASE slurm\_acct\_db;}
	
        Confirm with:

        \texttt{MariaDB [(none)]> SHOW DATABASES;}
	
      \item Create a slurm user and grant database access (replace '$<$pass$>$' with the value in \texttt{slurmdbd.conf}):

        \texttt{GRANT ALL ON slurm\_acct\_db.* TO 'slurm'@'\%' IDENTIFIED BY '<pass>' with grant option;}
	
        Confirm with:

        \texttt{MariaDB [(none)]> SELECT user, host, plugin FROM mysql.user;} \\
        \texttt{MariaDB [(none)]> SHOW GRANTS for slurm@localhost;}

      \item Review the current setting for MySQL's \texttt{innodb\_buffer\_pool\_size} before running the slurmdbd for the first time.

        \texttt{MariaDB [(none)]> SHOW VARIABLES LIKE innodb\_buffer\_pool\_size;}

      \item Consider setting this value large enough to handle the size of the database. This helps when converting large tables over to the new database schema and when purging old records. Setting \texttt{innodb\_lock\_wait\_timeout} and \texttt{innodb\_log\_file\_size} to larger values than the default is also recommended. Note: The default buffer size is 128M.

        These variables can be changed in one of the following files (not sure which one, but I suspect it's the first one):

        \texttt{/etc/mysql/conf.d/mysql.cnf} \\
        \texttt{/etc/mysql/mariadb.cnf} \\
        \texttt{/etc/mysql/mariadb.conf.d/*.cnf}

        \begin{verbatim}
		[mysqld]
		innodb_buffer_pool_size=256M
		innodb_log_file_size=256M
		innodb_lock_wait_timeout=1800
        \end{verbatim}

        To implement this change you must shut down the database and move/remove the log files:

        \begin{verbatim}
		sudo systemctl stop mariadb
		sudo rm /var/lib/mysql/ib_logfile?
		sudo systemctl start mariadb
        \end{verbatim}

        Verify the new buffer setting using the following command in the MariaDB shell:

        \texttt{MariaDB [(none)]> SHOW VARIABLES LIKE innodb\_buffer\_pool\_size;}

        This has been left as the default for now (obviously).

      \item Exit MariaDB:

        \texttt{MariaDB [(none)]> QUIT;}
    \end{enumerate}

  \item Start \texttt{slurmdbd}, acting on any issues that may appear:

    \texttt{sudo systemctl start slurmdbd}

    One issue I encountered was fixed by manually changing the owner of the database directory, and reinstall mariadb:
	
    \texttt{sudo chown mysql: /var/lib/mysql} \\
	\texttt{sudo apt install --reinstall mariadb-common mariadb-client mariadb-server}
	
	Try setting up the database again.

	If it's still grumpy, install \texttt{mysql-server-5.7} with \texttt{apt}, then try setting up the database again.

  \item Enable \texttt{mariadb} and \texttt{slurmdbd}.

%%%%%%%% ACCOUNTING SETUP %%%%%%%%

  \item For job accounting to work, the database and accounting tools must be configured as explained in \href{https://slurm.schedmd.com/accounting.html#database-configuration}{the official documentation}. Use \texttt{sacctmgr} to create and manage these records.

    Accounting records are maintained based on ``associations" consisting of four elements: cluster, account, user names and an optional partition name. All accounting things are lower case. \emph{You must define clusters before you add accounts and you must add accounts before you add users.}
%\url{https://wiki.fysik.dtu.dk/niflheim/Slurm_accounting}

    \begin{enumerate}
      \item Add the cluster to the database: \\
        \texttt{sacctmgr add cluster <clustername>}

      \item Add accounts: \\	
        \texttt{sacctmgr add account <account> [Cluster=<clustername>] [parent=<parent>] \textbackslash{}}\\ 
        \texttt{Description="<description>" Organization=<organization>} \\
        Omitting \texttt{Cluster} will add the account to all clusters. \texttt{parent} is only required if the new account is a sub-account of another account.

%		\input{./Chapters/ClusterAccts.tex}

      \item Add users: 

        \texttt{sacctmgr add user <username> [Account=<accounts>] [DefaultAccount=<account>]}

%        Is it \texttt{sacctmgr add user <username>} or \texttt{sacctmgr add user name=<username>}?

        \texttt{Account} can take a single account or a comma separated list. Not specifying \texttt{Account} will give the user access to all accounts on the cluster. \texttt{DefaultAccount} will set the default account for a user. At least one of the two options is required. \\

%        \input{./Chapters/ClusterAcctUsers.tex}

      \item Commands to view accounting information:

        \texttt{sacctmgr list cluster} \\
        \texttt{sacctmgr list configuration} \\
        \texttt{sacctmgr list stats}
	
    \end{enumerate}

%%%%%%%% v NEW v %%%%%%%%
  \item If other nodes than the \texttt{slurmdbd} node must be able to connect to the \texttt{slurmdbd} service, you must open the firewall to specific hosts. Please see the \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration}{Slurm\_configuration} page under the firewall section.

  \item Make the following changes in \texttt{slurmdbd.conf}:

    May want to set \texttt{PrivateData}

  \item Currently have no need to set up WCkeys. (\href{https://slurm.schedmd.com/wckey.html}{Workload characterization keys} are an orthogonal way to do accounting against possibly unrelated accounts. This can be useful where users from different accounts are all working on the same project.)

  \item \href{https://slurm.schedmd.com/qos.html}{QOS} includes multifactor job priority and job preemption. View with \texttt{sacctmgr}. By default everything is assigned normal. Can create something with higher priority.

  \item Job completion logging is redundant if using the accounting infrastructure.
%%%%%%%% ^ NEW ^ %%%%%%%%

%%%%%%%% PAM MODULE SETUP %%%%%%%%
  \item Don't set up PAM with the configuration we currently have! As long as users must submit from the node they want to run on, this is counterproductive!! For future use, see \href{https://wiki.fysik.dtu.dk/niflheim/Slurm_configuration#pam-module-restrictions}{this guide}.

%%%%%%%% START SLURM %%%%%%%%
  \item Enable and start all daemons: \texttt{mariadb}, \texttt{slurmdbd}, \texttt{slurmctld}, \texttt{slurmd}

  \item If you wish to customize \texttt{squeue} output, refer to section \ref{sec:customsqueue}
\end{enumerate}

%%
%%\section{MariaDB setup on new database host} \label{sec:movemariadb}
%%
%%\begin{enumerate}
%%  \item Find the current database directory. It should report back the default (\texttt{/var/lib/mysql}): \\
%%    \texttt{sudo mysql -e "SELECT @@datadir;"}
%%
%%  \item Stop the database daemons to avoid data corruption: \\
%%    \texttt{sudo systemctl stop slurmdbd} \\
%%    \texttt{sudo systemctl stop mariadb} \\
%%    \texttt{sudo systemctl is-active mariadb}
%%
%%  \item Create the new directory and change it's owner to \texttt{mysql}: \\
%%    \texttt{sudo mkdir /srv/mariadb-data} \\
%%    \texttt{sudo chown mysql: /srv/mariadb-data} 
%%
%%  \item Recursively copy the data to the new location: \\
%%    \texttt{sudo cp -R -p /var/lib/mysql/* /srv/mariadb-data}
%%
%%  \item Back up the original configuration files: \\
%%    \texttt{cd /etc/mysql} \\
%%    \texttt{sudo cp mysql.cnf mysql.cnf.backup} \\
%%    \texttt{sudo cp debian.cnf debian.cnf.backup} \\
%%    \texttt{sudo cp debian.cnf-5.7 debian.cnf-5.7.backup} \\
%%    \texttt{cd /etc/mysql/mariadb.conf.d} \\
%%    \texttt{sudo cp 50-server.cnf 50-server.cnf.backup} \\
%%    \texttt{sudo cp 50-client.cnf 50-client.cnf.backup}
%%
%%  \item Configure all the things: (\href{https://www.tecmint.com/change-default-mysql-mariadb-data-directory-in-linux/}{original source})
%%
%%    In \texttt{/etc/mysql}, replace \texttt{mysql.conf.d} with \texttt{mariadb.conf.d}.
%%
%%    In \texttt{/etc/mysql/debian.cnf-5.7}, replace both instances of \texttt{socket=\dots} with: \\
%%    \texttt{socket=/srv/mariadb-data/mysql.sock}
%%
%%    In \texttt{/etc/mysql/debian.cnf}, replace both instances of \texttt{socket=\dots} with: \\
%%    \texttt{socket=/srv/mariadb-data/mysql.sock}
%%
%%    In \texttt{/etc/mysql/mariadb.conf.d/50-client.cnf}, change the following under \texttt{[mysql]}: \\
%%    \texttt{socket=/srv/mariadb-data/mysql.sock} \\
%%    \texttt{port=3306} \texttt{\# new line}
%%
%%  In \texttt{/etc/mysql/mariadb.conf.d/50-server.cnf}, change the following under \texttt{[mysqld]}: \\
%%    \texttt{socket=/srv/mariadb-data/mysql.sock} \\
%%    \texttt{pid-file=/srv/mariadb-data/mysql.pid} \\
%%    \texttt{datadir=/srv/mariadb-data}
%%
%%  \item Start \texttt{mariadb} and check its status.
%%    \texttt{sudo systemctl daemon-reload} \\
%%    \texttt{sudo systemctl start mariadb} \\
%%    \texttt{sudo systemctl status mariadb}
%%
%%  \item Double check that the database directory has been updated: \\
%%    \texttt{sudo mysql -e "SELECT @@datadir;"}
%%
%%  \item Start \texttt{slurmdbd} and check it's status.
%%\end{enumerate}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\



